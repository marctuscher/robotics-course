{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline\n",
    "  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/niklas/git/uni/robotics-course/practical/clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niklas/.local/lib/python3.6/site-packages/quaternion/numba_wrapper.py:20: UserWarning: \n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Could not import from numba, which means that some\n",
      "parts of this code may run MUCH more slowly.  You\n",
      "may wish to install numba.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "  warnings.warn(warning_text)\n"
     ]
    }
   ],
   "source": [
    "# the following cells will use the rai framework for robot control, simulation and motion planning\n",
    "# https://github.com/MarcToussaint/rai\n",
    "import sys\n",
    "import os \n",
    "print(os.getcwd())\n",
    "# add the folder where libry.so is located to the path. Otherwise the import will crash.\n",
    "sys.path.append('../../ry/')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "import libry as ry\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import utils\n",
    "\n",
    "# add simulation. Note: if the string argument is not an empty string, a ROS node is started\n",
    "# and the joint state topics of the real baxter are subscribed. This won't work if you can't connect to Baxter.\n",
    "# In order to connect to Baxter, uncomment the next 2 lines and set the correct IP address:\n",
    "os.environ[\"ROS_MASTER_URI\"] = \"http://thecount.local:11311/\"\n",
    "os.environ[\"ROS_IP\"] = \"129.69.216.200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "total ERROR = 0.00241405\n",
    "total ERROR after radius correction = 0.00221046\n",
    "*** total Pinv:\n",
    "[0.00180045, 5.51994e-06, -0.569533, -0.0330757,\n",
    " -1.82321e-06, -0.00133149, 1.00136, 0.125005,\n",
    " 5.08217e-05, -0.00117336, -0.439092, 1.55487]\n",
    "*** camera intrinsics K:\n",
    "[555.197, -8.21031, -334.467,\n",
    " 0, -563.526, -271.392,\n",
    " 0, 0, -1.02162]\n",
    "*** camera world pos: [-0.0330757, 0.125005, 1.55487]\n",
    "*** camera world rot: [0.935411, 0.35328, -0.0133783, 0.00451155]\n",
    "\"\"\"\n",
    "cam_world_pos= [-0.0330757, 0.125005, 1.55487]\n",
    "cam_world_rot= [0.935411, 0.35328, -0.0133783, 0.00451155]\n",
    "chestCamIntrinsics = {'fx': 555.197 , \n",
    "                       'fy':  -563.526, \n",
    "                       'cx': -334.467, \n",
    "                       'cy': -271.392, 'width': 640, 'height':480}\n",
    "cam_rot = [0.935411, 0.35328, -0.0133783, 0.00451155]\n",
    "K = np.array([\n",
    "[555.197, -8.21031, -334.467],\n",
    " [0, -563.526, -271.392],\n",
    " [0, 0, -1.02162]\n",
    "])\n",
    "pinv_chest = np.array([[0.00180045, 5.51994e-06, -0.569533, -0.0330757],\n",
    "  [-1.82321e-06, -0.00133149, 1.00136, 0.125005],\n",
    "  [5.08217e-05, -0.00117336, -0.439092, 1.55487]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear views, config and operate by setting shared pointers to 0. Otherwise the notebook has to be restarted,\n",
    "# which is pretty annoying.\n",
    "C = 0\n",
    "v = 0\n",
    "B = 0\n",
    "gc.collect()\n",
    "    \n",
    "# initialize config\n",
    "C = ry.Config()\n",
    "v = C.view()\n",
    "C.clear()\n",
    "C.addFile('../../rai-robotModels/baxter/baxter_new.g')\n",
    "cam = C.addObject(name=\"cam\", parent=\"base_footprint\", shape=ry.ST.sphere, size=[0.01], color=[0,1,0], pos=cam_world_pos, quat=cam_world_rot)\n",
    "nodeName = \"camMarc\"\n",
    "\n",
    "q_home = C.getJointState()\n",
    "q_zero = q_home.copy() * 0.\n",
    "B = C.operate(nodeName)\n",
    "B.sync(C)\n",
    "C.makeObjectsConvex()\n",
    "B.sendToReal(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_target(targetFrame):\n",
    "    if not targetFrame in C.getFrameNames():\n",
    "        frame = C.addObject(name=targetFrame, parent=\"base_footprint\" ,shape=ry.ST.sphere, size=[.01], pos=[0,0,0], color=[0.,0.,1.])\n",
    "    return C.frame(targetFrame)\n",
    "\n",
    "def close_gripper(close=True):\n",
    "    B.sync(C)\n",
    "    q = C.getJointState()\n",
    "    if close:\n",
    "        q[-2] = 0.04\n",
    "    else:\n",
    "        q[-2] = 0\n",
    "    B.moveHard(q)\n",
    "\n",
    "def plan_path(targetPos, angle, targetFrame, gripperFrame, steps, time):\n",
    "    intermediatePos = cam_world_pos + 0.9 * (targetPos - cam_world_pos)\n",
    "    intermediate = check_target(\"intermediate\")\n",
    "    target = check_target(targetFrame)\n",
    "    rotA = utils.rotz(angle)\n",
    "    rotC = utils.quat2rotm(cam_rot)\n",
    "    rotM = rotA @ rotC\n",
    "    B.sync(C)\n",
    "    quat = utils.rotm2quat(rotM)\n",
    "    target.setPosition(targetPos)\n",
    "    intermediate.setPosition(intermediatePos)\n",
    "    target.setQuaternion(quat)\n",
    "    pp = C.komo_path(1, 30, 10, False)\n",
    "    pp.setConfigurations(C)\n",
    "    pp.clearObjectives()\n",
    "    pp.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductYZ, frames=[gripperFrame, targetFrame], target=[0], time=[.5, 1])\n",
    "    pp.addObjective(type= ry.OT.eq, feature= ry.FS.scalarProductZZ, frames= [gripperFrame, \"cam\"], target= [1], time= [.5, 1])\n",
    "    #pp.addObjective(type= ry.OT.sos,feature= ry.FS.qItself, frames= [], target= q_home, time=[1.])\n",
    "    pp.addObjective(type= ry.OT.eq, feature= ry.FS.distance, frames= [gripperFrame, 'intermediate'], target= [0], time= [.5])\n",
    "    pp.addObjective(type= ry.OT.eq, feature= ry.FS.positionDiff, frames= [gripperFrame, targetFrame], target=[0,0,-0.04],time= [1.])\n",
    "    pp.addObjective(type= ry.OT.sos, feature= ry.FS.qItself, frames= [], order= 1,  time= [0, 1])\n",
    "    pp.optimize(False)\n",
    "    t = pp.getT()\n",
    "    path = []\n",
    "    for i in range(t):\n",
    "        frames = pp.getConfiguration(i)\n",
    "        C.setFrameState(frames)\n",
    "        q = C.getJointState()\n",
    "        q[-2] = 0\n",
    "        q[-1] = 0\n",
    "        path += [q]\n",
    "    return path, pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.sendToReal(True)\n",
    "B.moveHard(q_home)\n",
    "close_gripper(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.sendToReal(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.moveHard(q_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webserver import sampleClient\n",
    "import vision\n",
    "import cv2\n",
    "from skimage import measure, morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = ry.Camera(\"camMarc\", \"/camera/rgb/image_rect_color\", \"/camera/depth/image_rect_raw\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cam.getRgb()\n",
    "d = cam.getDepth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc1638e8908>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm, m = vision.maskDepth(d, 0.7,1.4 )\n",
    "m = cv2.medianBlur(m.astype(np.uint8), 5)\n",
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleClient.predictRgb(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmask = sampleClient.predictMask(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 480, 640)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmask[\"masks\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "STANDARD_COLORS = [\n",
    "    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n",
    "    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n",
    "    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n",
    "    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
    "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n",
    "    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
    "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n",
    "    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
    "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n",
    "    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
    "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n",
    "    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
    "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n",
    "    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
    "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n",
    "    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
    "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n",
    "    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
    "    'Red', 'RosyBrown', 'RoyalBlue', 'SaddleBrown', 'Green', 'SandyBrown',\n",
    "    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
    "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n",
    "    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n",
    "    'WhiteSmoke', 'Yellow', 'YellowGreen'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "colors.to_rgb(\"AliceBlue\")\n",
    "image = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) /io/opencv/modules/imgproc/src/contours.cpp:197: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-16fd687774f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTANDARD_COLORS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"masks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"masks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcnts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcnts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misContourConvex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.0) /io/opencv/modules/imgproc/src/contours.cpp:197: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n"
     ]
    }
   ],
   "source": [
    "rcolors = np.random.randint(0, len(STANDARD_COLORS), size=len(segmask[\"masks\"]))\n",
    "for i, mask in enumerate(segmask[\"masks\"]):\n",
    "    cnts = cv2.findContours(mask.astype(np.uint8),4, 8)\n",
    "    for cn in cnts[0]:\n",
    "        if not cv2.isContourConvex(cn):\n",
    "            continue\n",
    "    plt.figure()\n",
    "    plt.imshow(mask)\n",
    "    c = colors.to_rgb(STANDARD_COLORS[rcolors[i]])\n",
    "    mask = np.bitwise_and(mask.astype(np.bool), m.astype(np.bool))\n",
    "    colored = np.ones((*mask.shape, 3)) * c\n",
    "    colored[~mask.astype(np.bool)] = 0\n",
    "    image = cv2.addWeighted(image.astype(np.uint8),1, (colored * 255).astype(np.uint8), 0.9, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394 355\n",
      "382 322\n",
      "447 307\n",
      "403 283\n",
      "285 207\n",
      "282 203\n",
      "380 352\n",
      "371 313\n",
      "355 297\n",
      "430 307\n",
      "364 266\n",
      "355 321\n",
      "440 334\n",
      "362 288\n",
      "388 344\n",
      "418 337\n",
      "360 324\n",
      "320 288\n",
      "611 292\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-189728b7653c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gx = 0\n",
    "gy = 0 \n",
    "def mouse_callback(event, x, y, flags, params):\n",
    "\n",
    "    #right-click event value is 2\n",
    "    if event == 1:\n",
    "        global gx, gy\n",
    "\n",
    "        #store the coordinates of the right-click event\n",
    "\n",
    "        gx = x\n",
    "        gy = y\n",
    "        #this just verifies that the mouse data is being collected\n",
    "        #you probably want to remove this later\n",
    "        print(gx, gy)\n",
    "\n",
    "\n",
    "#set mouse callback function for window\n",
    "scale_width = 640 / image.shape[1]\n",
    "scale_height = 480 / image.shape[0]\n",
    "scale = min(scale_width, scale_height)\n",
    "window_width = int(image.shape[1] * scale)\n",
    "window_height = int(image.shape[0] * scale)\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', window_width, window_height)\n",
    "cv2.setMouseCallback('image', mouse_callback)\n",
    "while(1):\n",
    "    cv2.imshow('image',image)\n",
    "    k = cv2.waitKey(20) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('a'):\n",
    "        print (gx,gy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grasp = sampleClient.predictGQCNN_pj(img, d, host=\"http://multitask.ddnss.de:5000\", segmask=m, **chestCamIntrinsics)\n",
    "vision.plotCircleAroundCenter(img, grasp[\"x\"], grasp[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp = sampleClient.predictFCGQCNN_pj(img, d, m,host=\"http://multitask.ddnss.de:5000\", **chestCamIntrinsics)\n",
    "vision.plotCircleAroundCenter(img, grasp[\"x\"], grasp[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_p, x, y = vision.getGraspPosition_noIntr(d,grasp[\"x\"], grasp[\"y\"])\n",
    "x = pinv_chest @ np.array(list(grasp_p) + [1])\n",
    "steps = 30; time = 10\n",
    "B.sendToReal(False)\n",
    "B.moveHard(q_home)\n",
    "p, pp = plan_path(x, grasp[\"angle\"], \"ball\", \"baxterR\", steps, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.sendToReal(True)\n",
    "close_gripper(False)\n",
    "B.move(p, [time/steps * i for i in range(len(p))], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_gripper(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.moveHard(q_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.sendToReal(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.sendToReal(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
